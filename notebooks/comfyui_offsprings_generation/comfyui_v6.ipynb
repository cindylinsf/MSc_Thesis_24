{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offspring Generation with ComfyUI - Version 6 (hopefully the last!)\n",
    "\n",
    "This time, adding ImageBlend node in ComfyUI to blend the two input photos.\n",
    "\n",
    "\n",
    "The scenarios include:\n",
    "1. `rand_blend{ratio}`: blend_factor randomly between 0.2-0.8\n",
    "2. `donor_blend80`: blend_factor = 0.8, 80% donor image\n",
    "3. `image_blend50`: blend_factor = 0.5, 50% donor + 50% my image\n",
    "4. `me_blend80`: blend_factor = 0.2, 20% donor image\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "import logging\n",
    "import shutil\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server-related imports\n",
    "import subprocess\n",
    "import webbrowser\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configurations\n",
    "COMFY_BASE = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI\")\n",
    "\n",
    "PATHS = {\n",
    "    'output': COMFY_BASE / \"output\",\n",
    "    'workflows': COMFY_BASE / \"output/workflows\",\n",
    "    'logs': COMFY_BASE / \"output/logs\",\n",
    "    'donors': Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/comfyui_source_files\"),\n",
    "    'my_photo': Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/cindy.jpg\")\n",
    "}\n",
    "\n",
    "BASE_WORKFLOW_PATH = PATHS['workflows'] / \"base_workflow_comfyui5.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend scenarios and naming\n",
    "BLEND_SCENARIOS = {\n",
    "    'random': (0.2, 0.8),  # Random blend ratio between 20-80% donor\n",
    "    'donor_dominant': 0.8,  # 80% donor, 20% me\n",
    "    'balanced': 0.5,       # 50% donor, 50% me\n",
    "    'me_dominant': 0.2     # 20% donor, 80% me\n",
    "}\n",
    "\n",
    "OUTPUT_NAMING = {\n",
    "    'random': 'rand_blend{ratio}',  # Will show actual blend ratio e.g., rand_blend65 means 65% donor\n",
    "    'donor_dominant': 'donor_blend80',\n",
    "    'balanced': 'image_blend50',\n",
    "    'me_dominant': 'me_blend80'\n",
    "}\n",
    "\n",
    "# Model parameters (keeping some consistent settings)\n",
    "MODEL_PARAMS = {\n",
    "    'denoise': 0.7,       # Keeping this constant since we're using image blending\n",
    "    'cfg_scale': 7.5,\n",
    "    'steps': 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt variations and model parameters\n",
    "PROMPT_VARIATIONS = {\n",
    "    'age_range': (10, 14),  # months\n",
    "    'expressions': [\n",
    "        'candid', 'curious', 'happy', 'neutral', \n",
    "        'gentle smile', 'attentive', 'peaceful'\n",
    "    ],\n",
    "    'lighting_conditions': [\n",
    "        'natural daylight', 'soft studio lighting', \n",
    "        'gentle window light', 'professional portrait lighting'\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "MODEL_PARAMS = {\n",
    "    'denoise_strength': (0.4, 0.7),\n",
    "    'cfg_scale': (4, 7),\n",
    "    'controlnet_strength': (0.6, 0.8),\n",
    "    'steps': (25, 40)  # Keep steps in reasonable range for SDXL Turbo\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def setup_directories() -> None:\n",
    "    \"\"\"Create necessary directories and verify paths.\"\"\"\n",
    "    try:\n",
    "        for name, path in PATHS.items():\n",
    "            if name != 'my_photo':\n",
    "                path.mkdir(parents=True, exist_ok=True)\n",
    "                logging.info(f\"Created/verified directory: {path}\")\n",
    "        \n",
    "        # Verify my_photo exists\n",
    "        if not PATHS['my_photo'].exists():\n",
    "            raise FileNotFoundError(f\"My photo not found at: {PATHS['my_photo']}\")\n",
    "        \n",
    "        # Load and verify base workflow exists\n",
    "        if not BASE_WORKFLOW_PATH.exists():\n",
    "            raise FileNotFoundError(f\"Base workflow not found at: {BASE_WORKFLOW_PATH}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in directory setup: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def generate_random_prompt() -> str:\n",
    "    \"\"\"Generate a randomized prompt with variations.\"\"\"\n",
    "    age = random.randint(*PROMPT_VARIATIONS['age_range'])\n",
    "    expression = random.choice(PROMPT_VARIATIONS['expressions'])\n",
    "    lighting = random.choice(PROMPT_VARIATIONS['lighting_conditions'])\n",
    "    \n",
    "    return (\n",
    "        f\"portrait of a {age} month old baby with distinctive facial features, \"\n",
    "        f\"{expression} expression, detailed facial features, {lighting}, \"\n",
    "        f\"high quality photograph, photorealistic\"\n",
    "    )\n",
    "\n",
    "def get_output_filename(donor_id: str, scenario: str, params: Dict) -> str:\n",
    "    \"\"\"Generate output filename based on scenario.\"\"\"\n",
    "    if scenario == 'random':\n",
    "        strength_int = int(params['controlnet_strength'] * 100)\n",
    "        suffix = f\"rand{strength_int}\"\n",
    "    else:\n",
    "        suffix_map = {\n",
    "            'donor_dominant': 'donor80',\n",
    "            'balanced': 'blend50',\n",
    "            'me_dominant': 'me80'\n",
    "        }\n",
    "        suffix = suffix_map[scenario]\n",
    "    \n",
    "    return f\"{donor_id}_{suffix}.png\"\n",
    "\n",
    "def get_random_parameters(scenario: str) -> Dict:\n",
    "    \"\"\"Generate random parameters for a specific scenario.\"\"\"\n",
    "    # Get blend factor based on scenario\n",
    "    if scenario == 'random':\n",
    "        blend_factor = round(random.uniform(*BLEND_SCENARIOS['random']), 2)\n",
    "    else:\n",
    "        blend_factor = BLEND_SCENARIOS[scenario]\n",
    "    \n",
    "    return {\n",
    "        'blend_factor': blend_factor,  # This controls donor percentage\n",
    "        'denoise': 0.7,  # Keep this constant now since we're focusing on blending\n",
    "        'cfg': 7.5,\n",
    "        'steps': 30,\n",
    "        'seed': random.randint(1, 2**32 - 1),\n",
    "        'prompt': generate_random_prompt()\n",
    "    }\n",
    "    \n",
    "    prompt = f\"portrait of a {age} month old baby with distinctive facial features, {expression} expression, detailed facial features, {lighting}, high quality photograph, photorealistic\"\n",
    "    \n",
    "    return {\n",
    "        'controlnet_strength': controlnet_strength,\n",
    "        'denoise': round(random.uniform(0.4, 0.7), 2),\n",
    "        'cfg': round(random.uniform(4, 7), 1),\n",
    "        'steps': random.randint(25, 40),\n",
    "        'seed': random.randint(1, 2**32 - 1),\n",
    "        'prompt': prompt\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logging Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging Classes\n",
    "class GenerationLogger:\n",
    "    \"\"\"Handles logging of generation parameters and results.\n",
    "    Creates two types of logs:\n",
    "    1. CSV log for quick overview\n",
    "    2. Detailed JSON logs for each generation\"\"\"\n",
    "    \n",
    "    def __init__(self, log_dir: Path):\n",
    "        self.log_dir = log_dir\n",
    "        self.csv_path = log_dir / 'generation_log.csv'\n",
    "        self.json_dir = log_dir / 'detailed_logs'\n",
    "        self.json_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize CSV if it doesn't exist\n",
    "        if not self.csv_path.exists():\n",
    "            self._initialize_csv()\n",
    "    \n",
    "    def _initialize_csv(self):\n",
    "        headers = [\n",
    "            'timestamp', 'donor_id', 'scenario',\n",
    "            'donor_strength', 'me_strength',\n",
    "            'seed', 'denoise', 'cfg',\n",
    "            'steps', 'controlnet_strength',\n",
    "            'output_filename', 'prompt'\n",
    "        ]\n",
    "        with open(self.csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(headers)\n",
    "    \n",
    "    def log_generation(self, \n",
    "                      donor_id: str,\n",
    "                      scenario: str,\n",
    "                      parameters: Dict,\n",
    "                      output_filename: str,\n",
    "                      prompt: str):\n",
    "        \"\"\"Log a single generation to both CSV and JSON.\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # CSV logging\n",
    "        csv_row = [\n",
    "            timestamp, donor_id, scenario,\n",
    "            parameters['donor_strength'], parameters['me_strength'],\n",
    "            parameters['seed'], parameters['denoise'],\n",
    "            parameters['cfg'], parameters['steps'],\n",
    "            parameters['controlnet_strength'],\n",
    "            output_filename, prompt\n",
    "        ]\n",
    "        \n",
    "        with open(self.csv_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(csv_row)\n",
    "        \n",
    "        # Detailed JSON logging\n",
    "        json_log = {\n",
    "            'timestamp': timestamp,\n",
    "            'donor_id': donor_id,\n",
    "            'scenario': scenario,\n",
    "            'parameters': parameters,\n",
    "            'output_filename': output_filename,\n",
    "            'prompt': prompt\n",
    "        }\n",
    "        \n",
    "        json_path = self.json_dir / f\"{donor_id}_{timestamp}.json\"\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(json_log, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Workflow Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Tracking\n",
    "class WorkflowTracker:\n",
    "    \"\"\"Tracks the progress of workflow processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, tracker_dir: Path):\n",
    "        self.tracker_dir = tracker_dir\n",
    "        self.tracker_file = tracker_dir / 'processed_workflows.csv'\n",
    "        self._initialize_tracker()\n",
    "        \n",
    "    def _initialize_tracker(self):\n",
    "        \"\"\"Initialize tracker file if it doesn't exist.\"\"\"\n",
    "        if not self.tracker_file.exists():\n",
    "            with open(self.tracker_file, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\n",
    "                    'workflow_file', 'donor_id', 'scenario', \n",
    "                    'timestamp', 'processed', 'notes'\n",
    "                ])\n",
    "    \n",
    "    def add_workflow(self, workflow_file: str, donor_id: str, scenario: str):\n",
    "        \"\"\"Add new workflow to tracking.\"\"\"\n",
    "        with open(self.tracker_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                workflow_file,\n",
    "                donor_id,\n",
    "                scenario,\n",
    "                datetime.now().strftime('%Y%m%d_%H%M%S'),\n",
    "                'No',\n",
    "                ''\n",
    "            ])\n",
    "    \n",
    "    def mark_processed(self, workflow_file: str, notes: str = ''):\n",
    "        \"\"\"Mark workflow as processed and add any notes about the result.\"\"\"\n",
    "        # Read existing data\n",
    "        with open(self.tracker_file, 'r', newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = list(reader)\n",
    "            header = data[0]\n",
    "            rows = data[1:]\n",
    "        \n",
    "        # Update processed status\n",
    "        for row in rows:\n",
    "            if row[0] == workflow_file:\n",
    "                row[4] = 'Yes'\n",
    "                row[5] = notes\n",
    "        \n",
    "        # Write back\n",
    "        with open(self.tracker_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header)\n",
    "            writer.writerows(rows)\n",
    "    \n",
    "    def get_unprocessed(self) -> List[str]:\n",
    "        \"\"\"Get list of unprocessed workflows.\"\"\"\n",
    "        unprocessed = []\n",
    "        with open(self.tracker_file, 'r', newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)  # Skip header\n",
    "            for row in reader:\n",
    "                if row[4] == 'No':\n",
    "                    unprocessed.append(row[0])\n",
    "        return unprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowManager:\n",
    "    \"\"\"Handles workflow creation and modification.\"\"\"\n",
    "    def __init__(self, base_workflow_path: Path):\n",
    "        self.base_workflow_path = base_workflow_path\n",
    "        self.load_base_workflow()\n",
    "    \n",
    "    def load_base_workflow(self):\n",
    "        \"\"\"Load the base workflow JSON.\"\"\"\n",
    "        try:\n",
    "            with open(self.base_workflow_path, 'r') as f:\n",
    "                self.base_workflow = json.load(f)\n",
    "            logging.info(\"Base workflow loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading base workflow: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def create_variation_workflow(self, donor_photo_path: Path, parameters: Dict, output_filename: str) -> Dict:\n",
    "        \"\"\"Create a workflow variation with specified parameters.\"\"\"\n",
    "        workflow = self.base_workflow.copy()\n",
    "        \n",
    "        # Strip the .png extension for the SaveImage node\n",
    "        output_name = output_filename.replace('.png', '')\n",
    "        \n",
    "        # Update nodes\n",
    "        for node in workflow['nodes']:\n",
    "            if node['type'] == 'LoadImage':\n",
    "                if node['id'] == 1:  # My photo\n",
    "                    node['widgets_values'] = [str(PATHS['my_photo']), \"image\"]\n",
    "                elif node['id'] == 2:  # Donor photo\n",
    "                    node['widgets_values'] = [str(donor_photo_path), \"image\"]\n",
    "            \n",
    "            # Update ImageBlend blend_factor\n",
    "            elif node['type'] == 'ImageBlend':\n",
    "                node['widgets_values'] = [\n",
    "                    parameters['blend_factor'],  # This controls donor percentage\n",
    "                    \"normal\"\n",
    "                ]\n",
    "            \n",
    "            # Update KSampler parameters\n",
    "            elif node['type'] == 'KSampler':\n",
    "                node['widgets_values'] = [\n",
    "                    parameters['seed'],\n",
    "                    \"randomize\",\n",
    "                    parameters['steps'],\n",
    "                    parameters['cfg'],\n",
    "                    \"euler\",\n",
    "                    \"normal\",\n",
    "                    parameters['denoise']\n",
    "                ]\n",
    "            \n",
    "            # Update SaveImage filename\n",
    "            elif node['type'] == 'SaveImage':\n",
    "                node['widgets_values'] = [output_name]\n",
    "        \n",
    "        return workflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Server Management and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server Management\n",
    "def start_comfyui_server():\n",
    "    \"\"\"Start ComfyUI server and open browser interface.\n",
    "    IMPORTANT: Keep this notebook running while using ComfyUI\"\"\"\n",
    "    try:\n",
    "        server_process = subprocess.Popen(\n",
    "            ['python', str(COMFY_BASE / 'main.py'), '--listen', '0.0.0.0', '--port', '8188'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "\n",
    "        # Wait for server to start\n",
    "        sleep(5)\n",
    "\n",
    "        # Open the UI in default browser\n",
    "        webbrowser.open('http://localhost:8188')\n",
    "        \n",
    "        print(\"ComfyUI server started! The interface should open in your browser.\")\n",
    "        print(\"Keep this notebook running while running ComfyUI.\")\n",
    "        \n",
    "        return server_process\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to start ComfyUI server: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_donor_batch():\n",
    "    \"\"\"Process a batch of donors with different scenarios.\"\"\"\n",
    "    try:\n",
    "        # Initialize components\n",
    "        setup_directories()\n",
    "        workflow_manager = WorkflowManager(BASE_WORKFLOW_PATH)\n",
    "        \n",
    "        # Get donor files\n",
    "        donor_files = sorted(list(PATHS['donors'].glob(\"*.jpeg\")))\n",
    "        logging.info(f\"Found {len(donor_files)} donor files to process\")\n",
    "        \n",
    "        # Process each donor\n",
    "        for donor_idx, donor_path in enumerate(donor_files, 1):\n",
    "            donor_id = donor_path.stem\n",
    "            logging.info(f\"\\nProcessing donor {donor_idx}/{len(donor_files)}: {donor_id}\")\n",
    "            \n",
    "            # Process each scenario\n",
    "            for scenario in CONTROLNET_SCENARIOS.keys():\n",
    "                try:\n",
    "                    # Get parameters\n",
    "                    parameters = get_random_parameters(scenario)\n",
    "                    \n",
    "                    # Generate output filename\n",
    "                    if scenario == 'random':\n",
    "                        strength_int = int(parameters['denoise'] * 100)\n",
    "                        output_filename = f\"{donor_id}_rand{strength_int}\"\n",
    "                    else:\n",
    "                        scenario_suffix = {\n",
    "                            'donor_dominant': 'donor80',\n",
    "                            'balanced': 'blend50',\n",
    "                            'me_dominant': 'me80'\n",
    "                        }[scenario]\n",
    "                        output_filename = f\"{donor_id}_{scenario_suffix}\"\n",
    "                    \n",
    "                    # Create and save workflow\n",
    "                    workflow = workflow_manager.create_variation_workflow(\n",
    "                        donor_path,\n",
    "                        parameters,\n",
    "                        output_filename\n",
    "                    )\n",
    "                    \n",
    "                    # Save workflow\n",
    "                    workflow_file = f\"{output_filename}.json\"\n",
    "                    workflow_path = PATHS['workflows'] / workflow_file\n",
    "                    \n",
    "                    with open(workflow_path, 'w') as f:\n",
    "                        json.dump(workflow, f, indent=2)\n",
    "                    \n",
    "                    logging.info(f\"✓ Created workflow for {scenario} scenario: {output_filename}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing {donor_id} - {scenario}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if donor_idx % 10 == 0:\n",
    "                logging.info(f\"Completed {donor_idx}/{len(donor_files)} donors\")\n",
    "            \n",
    "            time.sleep(1)  # Brief pause between donors\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Batch processing error: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    logging.info(\"Batch processing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComfyUI server started! The interface should open in your browser.\n",
      "Keep this notebook running while running ComfyUI.\n"
     ]
    }
   ],
   "source": [
    "# Start ComfyUI server\n",
    "server = start_comfyui_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process All Donors\n",
    "# If this is commented out it's because sometimes ComfyUI gets stuck \n",
    "# and I had to restart the notebook to restart the server\n",
    "\n",
    "# print(\"Starting batch processing...\")\n",
    "# proceed = input(\"Press Enter to continue or Ctrl+C to cancel...\")\n",
    "# process_donor_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Progress\n",
    "# # Run this cell to check remaining workflows\n",
    "# unprocessed = check_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper function to mark workflows as processed\n",
    "# def mark_workflow_complete(workflow_file: str, notes: str = \"Generated successfully\"):\n",
    "#     \"\"\"Mark a workflow as completed after running it in ComfyUI.\n",
    "#     Usage: mark_workflow_complete(\"donor_id_scenario.json\")\"\"\"\n",
    "#     tracker = WorkflowTracker(PATHS['logs'])\n",
    "#     tracker.mark_processed(workflow_file, notes)\n",
    "#     print(f\"Marked {workflow_file} as processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
