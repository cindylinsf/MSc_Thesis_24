{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and Standarizing Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in bank1:\n",
      "['headline', 'donor_description', 'donor_lookalikes', 'height', 'weight', 'eye_color', 'hair_color', 'hair_texture', 'ethnic_origin', 'religion', 'jewish_ancestry', 'education_level', 'areas_of_study']\n",
      "\n",
      "Columns in bank2:\n",
      "['donor_description', 'donor_quote', 'interests_and_hobbies', 'skills', 'mother_ethnic_origin', 'father_ethnic_origin', 'donor_race', 'skin_tone', 'eye_color', 'hair_color', 'height', 'weight', 'education', 'occupation', 'nationality', 'religion']\n",
      "\n",
      "Columns in bank3:\n",
      "['donor_alias', 'height', 'weight', 'race', 'staff_impression']\n",
      "\n",
      "Columns in bank4:\n",
      "['description', 'height', 'weight', 'eye color', 'skin tone', 'hair', 'ancestry', 'ethnic background', 'degree', 'occupation', 'interests', 'age range at donation', 'astrological sign', 'favorite subject', 'religion', 'favorite pet', 'personal goals', 'talents/hobbies']\n",
      "\n",
      "Processing bank1...\n",
      "Completed processing bank1\n",
      "\n",
      "Processing bank2...\n",
      "Completed processing bank2\n",
      "\n",
      "Processing bank3...\n",
      "Completed processing bank3\n",
      "\n",
      "Processing bank4...\n",
      "Completed processing bank4\n",
      "\n",
      "Merging all datasets...\n",
      "\n",
      "Validation dataset saved to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/merged_donor_data_with_ids.csv\n",
      "Clean dataset saved to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/merged_donor_data.csv\n",
      "Total number of records: 1019\n",
      "\n",
      "Column statistics:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1019 entries, 0 to 1018\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   donor_id           1019 non-null   object\n",
      " 1   bank_source        1019 non-null   object\n",
      " 2   donor_description  1019 non-null   object\n",
      " 3   height             1008 non-null   object\n",
      " 4   weight             1008 non-null   object\n",
      " 5   eye_color          940 non-null    object\n",
      " 6   hair_color         940 non-null    object\n",
      " 7   skin_tone          505 non-null    object\n",
      " 8   education_level    940 non-null    object\n",
      " 9   education_field    431 non-null    object\n",
      " 10  ethnic_background  1008 non-null   object\n",
      " 11  religion           572 non-null    object\n",
      " 12  occupation         505 non-null    object\n",
      " 13  interests_hobbies  505 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 111.6+ KB\n",
      "None\n",
      "\n",
      "Records per bank:\n",
      "bank_source\n",
      "bank1    435\n",
      "bank4    390\n",
      "bank2    126\n",
      "bank3     68\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of cleaned descriptions:\n",
      "0    Doctor & Baker. always goes out of his way to ...\n",
      "1    Motivated Med Student. is an extroverted guy w...\n",
      "2    E-Sports Pro. has a wonderful, positive energy...\n",
      "3    An Enlightened Man. enjoys self-reflection and...\n",
      "4    Future Physician. This cell and molecular bio ...\n",
      "Name: donor_description, dtype: object\n",
      "\n",
      "Missing value counts:\n",
      "donor_id               0\n",
      "bank_source            0\n",
      "donor_description      0\n",
      "height                11\n",
      "weight                11\n",
      "eye_color             79\n",
      "hair_color            79\n",
      "skin_tone            514\n",
      "education_level       79\n",
      "education_field      588\n",
      "ethnic_background     11\n",
      "religion             447\n",
      "occupation           514\n",
      "interests_hobbies    514\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def read_datasets(file_paths):\n",
    "    \"\"\"\n",
    "    Read all datasets and return a dictionary of dataframes\n",
    "    Now using np.nan instead of \"NULL\" string\n",
    "    \"\"\"\n",
    "    dfs = {}\n",
    "    for bank, path in file_paths.items():\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"\\nColumns in {bank}:\")\n",
    "        print(df.columns.tolist())\n",
    "        df['bank_source'] = bank\n",
    "        df['donor_id'] = f\"{bank}_\" + df.index.astype(str)\n",
    "        # Using np.nan instead of \"NULL\" string\n",
    "        df = df.replace({\"NULL\": np.nan, \"\": np.nan})\n",
    "        dfs[bank] = df\n",
    "    return dfs\n",
    "\n",
    "def merge_description_fields(row, dataset):\n",
    "    \"\"\"\n",
    "    Merge different description fields based on dataset structure, separated by periods\n",
    "    Now handling np.nan values\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    if dataset == 'bank1':\n",
    "        if pd.notna(row.get('headline')):\n",
    "            descriptions.append(clean_ids_from_text(row['headline']))\n",
    "        if pd.notna(row.get('donor_description')):\n",
    "            descriptions.append(clean_ids_from_text(row['donor_description']))\n",
    "        if pd.notna(row.get('donor_lookalikes')):\n",
    "            descriptions.append(clean_ids_from_text(row['donor_lookalikes']))\n",
    "            \n",
    "    elif dataset == 'bank2':\n",
    "        if pd.notna(row.get('donor_description')):\n",
    "            descriptions.append(clean_ids_from_text(row['donor_description']))\n",
    "        if pd.notna(row.get('donor_quote')):\n",
    "            descriptions.append(clean_ids_from_text(row['donor_quote']))\n",
    "            \n",
    "    elif dataset == 'bank3':\n",
    "        if pd.notna(row.get('donor_alias')):\n",
    "            descriptions.append(clean_ids_from_text(row['donor_alias']))\n",
    "        if pd.notna(row.get('staff_impression')):\n",
    "            descriptions.append(clean_ids_from_text(row['staff_impression']))\n",
    "            \n",
    "    elif dataset == 'bank4':\n",
    "        if pd.notna(row.get('description')):\n",
    "            descriptions.append(clean_ids_from_text(row['description']))\n",
    "        if pd.notna(row.get('personal goals')):\n",
    "            descriptions.append(clean_ids_from_text(row['personal goals']))\n",
    "    \n",
    "    return '. '.join(filter(None, descriptions))\n",
    "\n",
    "def clean_and_standardize_df(df, dataset):\n",
    "    \"\"\"\n",
    "    Clean and standardize a single dataframe\n",
    "    Now using np.nan for missing values\n",
    "    \"\"\"\n",
    "    # Create standardized dataframe with required columns\n",
    "    standardized = pd.DataFrame()\n",
    "    \n",
    "    # Keep donor_id and bank_source for validation\n",
    "    standardized['donor_id'] = df['donor_id']\n",
    "    standardized['bank_source'] = df['bank_source']\n",
    "    \n",
    "    # Merge description fields\n",
    "    standardized['donor_description'] = df.apply(lambda x: merge_description_fields(x, dataset), axis=1)\n",
    "    \n",
    "    # Map physical attributes\n",
    "    standardized['height'] = df['height']\n",
    "    standardized['weight'] = df['weight']\n",
    "    \n",
    "    # Handle eye color\n",
    "    if 'eye_color' in df.columns:\n",
    "        standardized['eye_color'] = df['eye_color']\n",
    "    elif 'eye color' in df.columns:\n",
    "        standardized['eye_color'] = df['eye color']\n",
    "    else:\n",
    "        standardized['eye_color'] = np.nan\n",
    "    \n",
    "    # Handle hair color\n",
    "    if 'hair_color' in df.columns:\n",
    "        standardized['hair_color'] = df['hair_color']\n",
    "    elif 'hair' in df.columns:\n",
    "        standardized['hair_color'] = df['hair']\n",
    "    else:\n",
    "        standardized['hair_color'] = np.nan\n",
    "    \n",
    "    # Handle skin tone\n",
    "    if 'skin_tone' in df.columns:\n",
    "        standardized['skin_tone'] = df['skin_tone']\n",
    "    elif 'skin tone' in df.columns:\n",
    "        standardized['skin_tone'] = df['skin tone']\n",
    "    else:\n",
    "        standardized['skin_tone'] = np.nan\n",
    "    \n",
    "    # Handle education\n",
    "    if 'education_level' in df.columns:\n",
    "        standardized['education_level'] = df['education_level']\n",
    "        if 'areas_of_study' in df.columns:\n",
    "            standardized['education_field'] = df['areas_of_study']\n",
    "        else:\n",
    "            standardized['education_field'] = np.nan\n",
    "    elif 'education' in df.columns:\n",
    "        standardized['education_level'] = df['education']\n",
    "        standardized['education_field'] = np.nan\n",
    "    elif 'degree' in df.columns:\n",
    "        standardized['education_level'] = df['degree']\n",
    "        if 'favorite_subject' in df.columns:\n",
    "            standardized['education_field'] = df['favorite_subject']\n",
    "        else:\n",
    "            standardized['education_field'] = np.nan\n",
    "    else:\n",
    "        standardized['education_level'] = np.nan\n",
    "        standardized['education_field'] = np.nan\n",
    "    \n",
    "    # Handle ethnic background\n",
    "    ethnic_fields = []\n",
    "    if 'ethnic_origin' in df.columns:\n",
    "        ethnic_fields.append(df['ethnic_origin'])\n",
    "    if 'mother_ethnic_origin' in df.columns and 'father_ethnic_origin' in df.columns:\n",
    "        mother_ethnic = df['mother_ethnic_origin']\n",
    "        father_ethnic = df['father_ethnic_origin']\n",
    "        combined = f\"Mother: {mother_ethnic}. Father: {father_ethnic}\"\n",
    "        ethnic_fields.append(combined)\n",
    "    if 'donor_race' in df.columns:\n",
    "        ethnic_fields.append(df['donor_race'])\n",
    "    if 'race' in df.columns:\n",
    "        ethnic_fields.append(df['race'])\n",
    "    if 'ancestry' in df.columns:\n",
    "        ethnic_fields.append(df['ancestry'])\n",
    "    if 'ethnic background' in df.columns:\n",
    "        ethnic_fields.append(df['ethnic background'])\n",
    "    \n",
    "    standardized['ethnic_background'] = ethnic_fields[0] if ethnic_fields else np.nan\n",
    "    \n",
    "    # Handle religion\n",
    "    if 'religion' in df.columns:\n",
    "        standardized['religion'] = df['religion']\n",
    "    else:\n",
    "        standardized['religion'] = np.nan\n",
    "    \n",
    "    # Handle occupation\n",
    "    if 'occupation' in df.columns:\n",
    "        standardized['occupation'] = df['occupation']\n",
    "    else:\n",
    "        standardized['occupation'] = np.nan\n",
    "    \n",
    "    # Handle interests/hobbies\n",
    "    if 'interests_and_hobbies' in df.columns:\n",
    "        standardized['interests_hobbies'] = df['interests_and_hobbies']\n",
    "    elif 'talents/hobbies' in df.columns:\n",
    "        standardized['interests_hobbies'] = df['talents/hobbies']\n",
    "    elif 'interests' in df.columns:\n",
    "        standardized['interests_hobbies'] = df['interests']\n",
    "    else:\n",
    "        standardized['interests_hobbies'] = np.nan\n",
    "    \n",
    "    return standardized\n",
    "\n",
    "def main():\n",
    "    # Define file paths\n",
    "    file_paths = {\n",
    "        'bank1': '/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/bank1_processed_data.csv',\n",
    "        'bank2': '/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/bank2_processed_data.csv',\n",
    "        'bank3': '/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/bank3_processed_data.csv',\n",
    "        'bank4': '/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/bank4_processed_data.csv'\n",
    "    }\n",
    "    \n",
    "    # Read all datasets\n",
    "    dfs = read_datasets(file_paths)\n",
    "    \n",
    "    # Clean and standardize each dataset\n",
    "    standardized_dfs = []\n",
    "    for bank, df in dfs.items():\n",
    "        print(f\"\\nProcessing {bank}...\")\n",
    "        standardized_df = clean_and_standardize_df(df, bank)\n",
    "        standardized_dfs.append(standardized_df)\n",
    "        print(f\"Completed processing {bank}\")\n",
    "        \n",
    "    # Concatenate all standardized dataframes\n",
    "    print(\"\\nMerging all datasets...\")\n",
    "    final_df = pd.concat(standardized_dfs, ignore_index=True)\n",
    "    \n",
    "    # Save full version with IDs for validation\n",
    "    validation_path = Path('/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/merged_donor_data_with_ids.csv')\n",
    "    final_df.to_csv(validation_path, index=False)\n",
    "    \n",
    "    # Save clean version without IDs and bank source\n",
    "    clean_df = final_df.drop(['donor_id', 'bank_source'], axis=1)\n",
    "    clean_path = Path('/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/merged_donor_data.csv')\n",
    "    clean_df.to_csv(clean_path, index=False)\n",
    "    \n",
    "    print(f\"\\nValidation dataset saved to: {validation_path}\")\n",
    "    print(f\"Clean dataset saved to: {clean_path}\")\n",
    "    print(f\"Total number of records: {len(final_df)}\")\n",
    "    print(\"\\nColumn statistics:\")\n",
    "    print(final_df.info())\n",
    "    print(\"\\nRecords per bank:\")\n",
    "    print(final_df['bank_source'].value_counts())\n",
    "    print(\"\\nSample of cleaned descriptions:\")\n",
    "    print(final_df['donor_description'].head())\n",
    "    print(\"\\nMissing value counts:\")\n",
    "    print(final_df.isna().sum())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .csv File into .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1019 records to JSON\n",
      "Output saved to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/merged_donor_data.json\n",
      "\n",
      "Sample record structure:\n",
      "{\n",
      "  \"donor_description\": \"Doctor & Baker. always goes out of his way to do the right thing and help others, especially with their health. You might say that\\u2019s why he\\u2019s so dedicated to earning his degree as a Doctor of Pharmacy (3.99 GPA). Outside of his professional life, he enjoys many fascinating hobbies: learning to play the harmonium, gardening, and classic literature. With wavy, dark hair, this handsome donor also shows he cares by cooking and baking for others \\u2014 skills he learned from his mother and grandmother.\",\n",
      "  \"height\": \"5'9 (175cm)\",\n",
      "  \"weight\": \"173 lbs (78kg)\",\n",
      "  \"eye_color\": \"Brown\",\n",
      "  \"hair_color\": \"Dark Brown\",\n",
      "  \"skin_tone\": null,\n",
      "  \"education_level\": \"Postgraduate\",\n",
      "  \"education_field\": \"Pharmacy\",\n",
      "  \"ethnic_background\": \"East Indian\",\n",
      "  \"religion\": \"Hindu\",\n",
      "  \"occupation\": null,\n",
      "  \"interests_hobbies\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def convert_csv_to_json():\n",
    "    # Read the CSV file\n",
    "    input_path = Path('/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/merged_donor_data.csv')\n",
    "    output_path = Path('/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/processed/merged_donor_data.json')\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    # Convert DataFrame to list of dictionaries\n",
    "    # orient='records' creates an array of objects where each object is a row\n",
    "    json_data = json.loads(df.to_json(orient='records'))\n",
    "    \n",
    "    # Write to JSON file with proper formatting\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Converted {len(json_data)} records to JSON\")\n",
    "    print(f\"Output saved to: {output_path}\")\n",
    "    \n",
    "    # Show sample of first record\n",
    "    print(\"\\nSample record structure:\")\n",
    "    print(json.dumps(json_data[0], indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_csv_to_json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
