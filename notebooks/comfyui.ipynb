{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating offspring photos with ComfyUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/comfyanonymous/ComfyUI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch (from -r requirements.txt (line 1))\n",
      "  Downloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchsde (from -r requirements.txt (line 2))\n",
      "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting torchvision (from -r requirements.txt (line 3))\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio (from -r requirements.txt (line 4))\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting einops (from -r requirements.txt (line 5))\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting transformers>=4.28.1 (from -r requirements.txt (line 6))\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers>=0.13.3 (from -r requirements.txt (line 7))\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece (from -r requirements.txt (line 8))\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting safetensors>=0.4.2 (from -r requirements.txt (line 9))\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting aiohttp (from -r requirements.txt (line 10))\n",
      "  Downloading aiohttp-3.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting pyyaml (from -r requirements.txt (line 11))\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: Pillow in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (11.0.0)\n",
      "Collecting scipy (from -r requirements.txt (line 13))\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from -r requirements.txt (line 14))\n",
      "  Using cached tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (6.0.0)\n",
      "Collecting kornia>=0.7.1 (from -r requirements.txt (line 18))\n",
      "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting spandrel (from -r requirements.txt (line 19))\n",
      "  Downloading spandrel-0.4.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting soundfile (from -r requirements.txt (line 20))\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Collecting filelock (from torch->-r requirements.txt (line 1))\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
      "Collecting networkx (from torch->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch->-r requirements.txt (line 1))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch->-r requirements.txt (line 1))\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (71.0.4)\n",
      "Collecting sympy==1.13.1 (from torch->-r requirements.txt (line 1))\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r requirements.txt (line 1))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from torchsde->-r requirements.txt (line 2)) (2.1.2)\n",
      "Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n",
      "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers>=4.28.1->-r requirements.txt (line 6))\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (24.1)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.28.1->-r requirements.txt (line 6))\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2.32.3)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->-r requirements.txt (line 10))\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->-r requirements.txt (line 10))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from aiohttp->-r requirements.txt (line 10)) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->-r requirements.txt (line 10))\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->-r requirements.txt (line 10))\n",
      "  Downloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->-r requirements.txt (line 10))\n",
      "  Downloading propcache-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->-r requirements.txt (line 10))\n",
      "  Downloading yarl-1.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kornia-rs>=0.1.0 (from kornia>=0.7.1->-r requirements.txt (line 18))\n",
      "  Downloading kornia_rs-0.1.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting cffi>=1.0 (from soundfile->-r requirements.txt (line 20))\n",
      "  Downloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile->-r requirements.txt (line 20))\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 10)) (3.7)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->-r requirements.txt (line 1))\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cindylinsf/anaconda3/envs/thesis24/lib/python3.12/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2024.7.4)\n",
      "Downloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchaudio-2.5.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.8/381.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.6-cp312-cp312-macosx_11_0_arm64.whl (454 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Downloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spandrel-0.4.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.8/178.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading kornia_rs-0.1.7-cp312-cp312-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.8/284.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "Downloading yarl-1.17.2-cp312-cp312-macosx_11_0_arm64.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: trampoline, sentencepiece, mpmath, tqdm, sympy, scipy, safetensors, regex, pyyaml, pycparser, propcache, networkx, multidict, MarkupSafe, kornia-rs, fsspec, frozenlist, filelock, einops, aiohappyeyeballs, yarl, jinja2, huggingface-hub, cffi, aiosignal, torch, tokenizers, soundfile, aiohttp, transformers, torchvision, torchsde, torchaudio, kornia, spandrel\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.3 aiohttp-3.11.6 aiosignal-1.3.1 cffi-1.17.1 einops-0.8.0 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.10.0 huggingface-hub-0.26.2 jinja2-3.1.4 kornia-0.7.4 kornia-rs-0.1.7 mpmath-1.3.0 multidict-6.1.0 networkx-3.4.2 propcache-0.2.0 pycparser-2.22 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.4.5 scipy-1.14.1 sentencepiece-0.2.0 soundfile-0.12.1 spandrel-0.4.0 sympy-1.13.1 tokenizers-0.20.3 torch-2.5.1 torchaudio-2.5.1 torchsde-0.2.6 torchvision-0.20.1 tqdm-4.67.0 trampoline-0.1.2 transformers-4.46.3 yarl-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComfyUI directory found at /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI\n",
      "Added ComfyUI to system path\n"
     ]
    }
   ],
   "source": [
    "# Define my specific ComfyUI path\n",
    "COMFY_PATH = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI\")\n",
    "\n",
    "# Verify the path exists\n",
    "if not COMFY_PATH.exists():\n",
    "    raise Exception(f\"ComfyUI path not found at {COMFY_PATH}\")\n",
    "else:\n",
    "    print(f\"ComfyUI directory found at {COMFY_PATH}\")\n",
    "\n",
    "# Add ComfyUI to system path\n",
    "if str(COMFY_PATH) not in sys.path:\n",
    "    sys.path.append(str(COMFY_PATH))\n",
    "    print(\"Added ComfyUI to system path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(url, save_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    save_path = Path(save_path)\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(save_path, 'wb') as f, tqdm(\n",
    "        desc=save_path.name,\n",
    "        total=total_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True\n",
    "    ) as pbar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = f.write(data)\n",
    "            pbar.update(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directories\n",
    "models_path = COMFY_PATH / \"models\"\n",
    "checkpoints_path = models_path / \"checkpoints\"\n",
    "controlnet_path = models_path / \"controlnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created/verified directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/models\n",
      "Created/verified directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/models/checkpoints\n",
      "Created/verified directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/models/controlnet\n"
     ]
    }
   ],
   "source": [
    "# Create directories and print status\n",
    "for path in [models_path, checkpoints_path, controlnet_path]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created/verified directory: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the Model\n",
    "\n",
    "The workflow:\n",
    "\n",
    "Base Model (SD XL Turbo): We're using this because it's:\n",
    "- Faster than regular Stable Diffusion\n",
    "- Better at handling facial features\n",
    "- More consistent with human anatomy\n",
    "\n",
    "ControlNet Face: This will help:\n",
    "- Preserve important facial features from both you and the donors\n",
    "- Maintain consistent facial structure\n",
    "- Ensure realistic baby face generation\n",
    "\n",
    "\n",
    "IP-Adapter: This helps:\n",
    "- Better blend features from multiple images\n",
    "- Maintain genetic characteristics\n",
    "- Create more natural-looking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models we need with their URLs and purposes\n",
    "models = {\n",
    "    \"sd_xl_turbo\": {\n",
    "        \"url\": \"https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/sd_xl_turbo_1.0.safetensors\",\n",
    "        \"path\": checkpoints_path / \"sd_xl_turbo_1.0.safetensors\",\n",
    "        \"size\": \"6.9GB\",\n",
    "        \"purpose\": \"Base model - chosen for speed and quality in generating human faces\"\n",
    "    },\n",
    "    \"controlnet_face\": {\n",
    "        \"url\": \"https://huggingface.co/CrucibleAI/ControlNetMediaPipeFace/resolve/main/controlnet-mediapipe-face.safetensors\",\n",
    "        \"path\": controlnet_path / \"controlnet-mediapipe-face.safetensors\",\n",
    "        \"size\": \"1.4GB\",\n",
    "        \"purpose\": \"Ensures accurate facial feature preservation and transformation\"\n",
    "    },\n",
    "    \"ip_adapter\": {\n",
    "        \"url\": \"https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.safetensors\",\n",
    "        \"path\": models_path / \"ip_adapters\" / \"ip-adapter_sdxl_vit-h.safetensors\",\n",
    "        \"size\": \"0.7GB\",\n",
    "        \"purpose\": \"Helps blend facial features between input images\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to be downloaded:\n",
      "\n",
      "sd_xl_turbo:\n",
      "Size: 6.9GB\n",
      "Purpose: Base model - chosen for speed and quality in generating human faces\n",
      "Will be saved to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/models/checkpoints/sd_xl_turbo_1.0.safetensors\n",
      "\n",
      "controlnet_face:\n",
      "Size: 1.4GB\n",
      "Purpose: Ensures accurate facial feature preservation and transformation\n",
      "Will be saved to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/models/controlnet/controlnet-mediapipe-face.safetensors\n",
      "\n",
      "ip_adapter:\n",
      "Size: 0.7GB\n",
      "Purpose: Helps blend facial features between input images\n",
      "Will be saved to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/models/ip_adapters/ip-adapter_sdxl_vit-h.safetensors\n"
     ]
    }
   ],
   "source": [
    "# Print model information before downloading\n",
    "print(\"Models to be downloaded:\")\n",
    "for name, info in models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Size: {info['size']}\")\n",
    "    print(f\"Purpose: {info['purpose']}\")\n",
    "    print(f\"Will be saved to: {info['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading sd_xl_turbo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sd_xl_turbo_1.0.safetensors: 100%|██████████| 13.9G/13.9G [15:15<00:00, 15.2MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded sd_xl_turbo\n",
      "\n",
      "Downloading controlnet_face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "controlnet-mediapipe-face.safetensors: 100%|██████████| 15.0/15.0 [00:00<00:00, 109kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded controlnet_face\n",
      "\n",
      "Downloading ip_adapter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ip-adapter_sdxl_vit-h.safetensors: 100%|██████████| 698M/698M [00:51<00:00, 13.5MiB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded ip_adapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "proceed = input(\"\\nProceed with download? (yes/no): \")\n",
    "\n",
    "if proceed.lower() == 'yes':\n",
    "    for model_name, model_info in models.items():\n",
    "        if not model_info[\"path\"].exists():\n",
    "            print(f\"\\nDownloading {model_name}...\")\n",
    "            # Create parent directory if it doesn't exist\n",
    "            model_info[\"path\"].parent.mkdir(parents=True, exist_ok=True)\n",
    "            download_model(model_info[\"url\"], model_info[\"path\"])\n",
    "            print(f\"Downloaded {model_name}\")\n",
    "        else:\n",
    "            print(f\"\\n{model_name} already exists at {model_info['path']}\")\n",
    "else:\n",
    "    print(\"Download cancelled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the ComfyUI server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import webbrowser\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComfyUI server started! The interface should open in your browser.\n",
      "Keep this notebook running while you use ComfyUI.\n"
     ]
    }
   ],
   "source": [
    "# Start ComfyUI server\n",
    "server_process = subprocess.Popen(\n",
    "    ['python', str(COMFY_PATH / 'main.py'), '--listen', '0.0.0.0', '--port', '8188'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "\n",
    "# Wait a moment for the server to start\n",
    "sleep(5)\n",
    "\n",
    "# Open the UI in default browser\n",
    "webbrowser.open('http://localhost:8188')\n",
    "\n",
    "print(\"ComfyUI server started! The interface should open in your browser.\")\n",
    "print(\"Keep this notebook running while you use ComfyUI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_donor_folders(donor_filename):\n",
    "    \"\"\"\n",
    "    Creates the folder structure for a donor's generations\n",
    "    \"\"\"\n",
    "    donor_stem = Path(donor_filename).stem\n",
    "    donor_dir = PATHS[\"output\"] / \"donor_logs\" / donor_stem / \"v1\"\n",
    "    donor_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return donor_dir\n",
    "\n",
    "def create_generation_metadata(donor_filename, seeds, cfg=7.0, steps=25):\n",
    "    \"\"\"\n",
    "    Creates metadata for a single donor's generation session\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"donor_image\": donor_filename,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"generation_params\": {\n",
    "            \"cfg\": cfg,\n",
    "            \"steps\": steps,\n",
    "            \"sampler\": \"euler\",\n",
    "        },\n",
    "        \"seeds\": seeds,\n",
    "        \"output_files\": [\n",
    "            f\"{Path(donor_filename).stem}_baby_{i+1}.png\" \n",
    "            for i in range(len(seeds))\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def update_main_logs(metadata, csv_path, json_path):\n",
    "    \"\"\"\n",
    "    Updates both CSV and JSON logs with new generation data\n",
    "    \"\"\"\n",
    "    # Update JSON log\n",
    "    if json_path.exists():\n",
    "        with open(json_path, 'r') as f:\n",
    "            all_logs = json.load(f)\n",
    "    else:\n",
    "        all_logs = []\n",
    "    \n",
    "    all_logs.append(metadata)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(all_logs, f, indent=2)\n",
    "\n",
    "    # Update CSV log\n",
    "    csv_exists = csv_path.exists()\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not csv_exists:\n",
    "            writer.writerow([\n",
    "                'donor_image', 'timestamp', 'cfg', \n",
    "                'steps', 'sampler', 'seeds', 'output_files'\n",
    "            ])\n",
    "        writer.writerow([\n",
    "            metadata['donor_image'],\n",
    "            metadata['timestamp'],\n",
    "            metadata['generation_params']['cfg'],\n",
    "            metadata['generation_params']['steps'],\n",
    "            metadata['generation_params']['sampler'],\n",
    "            ','.join(map(str, metadata['seeds'])),\n",
    "            ','.join(metadata['output_files'])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input directory for my photo\n",
    "input_path = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input\")\n",
    "input_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Paths dictionary\n",
    "PATHS = {\n",
    "    \"donors\": Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/comfyui_source_files\"),\n",
    "    \"output\": Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings\"),\n",
    "    \"my_photo\": input_path / \"cindy.jpg\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found donors directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/comfyui_source_files\n",
      "✓ Found output directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings\n",
      "✓ Found my_photo directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/cindy.jpg\n"
     ]
    }
   ],
   "source": [
    "# Verify paths\n",
    "for name, path in PATHS.items():\n",
    "    if path.exists():\n",
    "        print(f\"✓ Found {name} directory: {path}\")\n",
    "    else:\n",
    "        if name == \"my_photo\":\n",
    "            print(f\"\\nPlease save your headshot photo as: {path}\")\n",
    "            print(\"Once saved, run this cell again to verify.\")\n",
    "        elif name == \"output\":\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Created output directory: {path}\")\n",
    "        else:\n",
    "            print(f\"❌ ERROR: {name} directory not found: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up previous setup and created fresh directory structure.\n",
      "ComfyUI output directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output\n",
      "Donor output directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/donor_logs/aug_gpt_4_gem_wo/v1\n"
     ]
    }
   ],
   "source": [
    "# Paths cleanup (to comply with ComfyUI's output structure)\n",
    "PATHS = {\n",
    "    \"donors\": Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/comfyui_source_files\"),\n",
    "    \"output\": Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings\"),\n",
    "    \"my_photo\": input_path / \"cindy.jpg\" \n",
    "}\n",
    "\n",
    "# 1. Clean up: Remove any previously created symlinks or directories\n",
    "project_outputs = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/thesis_outputs\")\n",
    "if project_outputs.exists():\n",
    "    if project_outputs.is_symlink():\n",
    "        project_outputs.unlink()\n",
    "    elif project_outputs.is_dir():\n",
    "        shutil.rmtree(project_outputs)\n",
    "\n",
    "# 2. Set up fresh directory structure in ComfyUI's output\n",
    "comfy_output = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output\")\n",
    "donor_output = comfy_output / \"donor_logs\" / \"aug_gpt_4_gem_wo\" / \"v1\"\n",
    "donor_output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Cleaned up previous setup and created fresh directory structure.\")\n",
    "print(f\"ComfyUI output directory: {comfy_output}\")\n",
    "print(f\"Donor output directory: {donor_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ComfyUI Workflow\n",
    "- Testing 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_seeds(count=3):\n",
    "    \"\"\"Generate list of random seeds for multiple generations\"\"\"\n",
    "    return [random.randint(1, 2**31 - 1) for _ in range(count)]\n",
    "\n",
    "# Test with our sample donor\n",
    "test_donor = PATHS[\"donors\"] / \"aug_gpt_4_gem_wo.jpeg\"\n",
    "donor_output_dir = setup_donor_folders(test_donor.name)\n",
    "\n",
    "# Generate seeds for our three variations\n",
    "seeds = generate_random_seeds(3)\n",
    "\n",
    "# Create workflow with corrected parameters\n",
    "updated_workflow = {\n",
    "    \"version\": 1.0,\n",
    "    \"state\": {},\n",
    "    \"nodes\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"type\": \"LoadImage\",\n",
    "            \"pos\": [50, 200],\n",
    "            \"size\": [315, 98],\n",
    "            \"flags\": {},\n",
    "            \"order\": 0,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"LoadImage\"},\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"IMAGE\",\n",
    "                    \"type\": \"IMAGE\",\n",
    "                    \"links\": [5],\n",
    "                    \"slot_index\": 0\n",
    "                }\n",
    "            ],\n",
    "            \"widgets_values\": [str(PATHS[\"my_photo\"])]\n",
    "        }\n",
    "    ]  # Closing the 'nodes' list\n",
    "}  # Closing the 'updated_workflow' dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Test donor: aug_gpt_4_gem_wo.jpeg\n",
      "Output directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings/donor_logs/aug_gpt_4_gem_wo/v1\n",
      "Seeds to be used: [773169767, 1547005295, 1737388557]\n"
     ]
    }
   ],
   "source": [
    "# Setup logging paths\n",
    "csv_log_path = PATHS[\"output\"] / \"all_generations_v1.csv\"\n",
    "json_log_path = PATHS[\"output\"] / \"all_generations_v1.json\"\n",
    "\n",
    "# Modify workflow for our test donor with the first seed\n",
    "def create_workflow_config(donor_image, output_dir, seed):\n",
    "    return {\n",
    "        \"3\": {  # CheckpointLoaderSimple node\n",
    "            \"inputs\": {},\n",
    "            \"class_type\": \"CheckpointLoaderSimple\",\n",
    "            \"widgets_values\": [\"sd_xl_turbo_1.0.safetensors\"]\n",
    "        },\n",
    "        \"5\": {  # KSampler node\n",
    "            \"inputs\": {\n",
    "                \"seed\": seed,\n",
    "                \"steps\": 25,\n",
    "                \"cfg\": 7.0,\n",
    "                \"sampler_name\": \"euler\",\n",
    "                \"scheduler\": \"normal\",\n",
    "                \"denoise\": 1.0,\n",
    "                \"model\": [\"3\", 0],\n",
    "                \"positive\": [\"4\", 0],\n",
    "                \"negative\": [\"9\", 0],\n",
    "                \"latent_image\": [\"8\", 0]\n",
    "            },\n",
    "            \"class_type\": \"KSampler\",\n",
    "        },\n",
    "        \"7\": {  # SaveImage node\n",
    "            \"inputs\": {\n",
    "                \"images\": [\"6\", 0],\n",
    "                \"filename_prefix\": Path(donor_image).stem + \"_baby\",\n",
    "                \"filename_separator\": \"_\"\n",
    "            },\n",
    "            \"class_type\": \"SaveImage\",\n",
    "            \"widgets_values\": [str(output_dir), \"\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Create and save complete workflow for test\n",
    "test_workflow_path = PATHS[\"output\"] / \"workflows\" / \"test_workflow.json\"\n",
    "test_workflow_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create metadata for our test generation\n",
    "test_metadata = create_generation_metadata(\n",
    "    test_donor.name,\n",
    "    seeds=seeds,\n",
    ")\n",
    "\n",
    "# Save initial metadata\n",
    "donor_metadata_path = donor_output_dir.parent / \"metadata_v1.json\"\n",
    "with open(donor_metadata_path, \"w\") as f:\n",
    "    json.dump(test_metadata, f, indent=2)\n",
    "\n",
    "print(f\"Setup complete!\")\n",
    "print(f\"Test donor: {test_donor.name}\")\n",
    "print(f\"Output directory: {donor_output_dir}\")\n",
    "print(f\"Seeds to be used: {seeds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using `json` workflow to test on 1 donor `aug_gpt_4_gem_wo.jpeg`\n",
    "- The output workflow json doc will be at: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings/donor_logs/aug_gpt_4_gem_wo/workflow.json\n",
    "- When it generated baby photos successfully, the template is saved as `base_workflow.json` is saved to `/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/user/default/workflows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the workflow for ComfyUI\n",
    "workflow_path = PATHS[\"output\"] / \"donor_logs\" / test_donor.stem / \"workflow.json\"\n",
    "workflow_path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def setup_donor_folders(donor_filename):\n",
    "    \"\"\"\n",
    "    Creates the folder structure for a donor's generations\n",
    "    \"\"\"\n",
    "    donor_stem = Path(donor_filename).stem\n",
    "    donor_dir = PATHS[\"output\"] / \"donor_logs\" / donor_stem / \"v1\"\n",
    "    donor_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return donor_dir\n",
    "\n",
    "def create_generation_metadata(donor_filename, seeds, cfg=7.0, steps=25):\n",
    "    \"\"\"\n",
    "    Creates metadata for a single donor's generation session\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"donor_image\": donor_filename,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"generation_params\": {\n",
    "            \"cfg\": cfg,\n",
    "            \"steps\": steps,\n",
    "            \"sampler\": \"euler\",\n",
    "        },\n",
    "        \"seeds\": seeds,\n",
    "        \"output_files\": [\n",
    "            f\"{Path(donor_filename).stem}_baby_{i+1}.png\" \n",
    "            for i in range(len(seeds))\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def update_main_logs(metadata, csv_path, json_path):\n",
    "    \"\"\"\n",
    "    Updates both CSV and JSON logs with new generation data\n",
    "    \"\"\"\n",
    "    # Update JSON log\n",
    "    if json_path.exists():\n",
    "        with open(json_path, 'r') as f:\n",
    "            all_logs = json.load(f)\n",
    "    else:\n",
    "        all_logs = []\n",
    "    \n",
    "    all_logs.append(metadata)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(all_logs, f, indent=2)\n",
    "\n",
    "    # Update CSV log\n",
    "    csv_exists = csv_path.exists()\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not csv_exists:\n",
    "            writer.writerow([\n",
    "                'donor_image', 'timestamp', 'cfg', \n",
    "                'steps', 'sampler', 'seeds', 'output_files'\n",
    "            ])\n",
    "        writer.writerow([\n",
    "            metadata['donor_image'],\n",
    "            metadata['timestamp'],\n",
    "            metadata['generation_params']['cfg'],\n",
    "            metadata['generation_params']['steps'],\n",
    "            metadata['generation_params']['sampler'],\n",
    "            ','.join(map(str, metadata['seeds'])),\n",
    "            ','.join(metadata['output_files'])\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for test generation\n",
    "# Generate random seeds\n",
    "seeds = [random.randint(1, 2**31 - 1) for _ in range(3)]\n",
    "\n",
    "# Test with our sample donor\n",
    "test_donor = PATHS[\"donors\"] / \"aug_gpt_4_gem_wo.jpeg\"\n",
    "donor_output_dir = setup_donor_folders(test_donor.name)\n",
    "\n",
    "# Setup logging paths\n",
    "csv_log_path = PATHS[\"output\"] / \"all_generations_v1.csv\"\n",
    "json_log_path = PATHS[\"output\"] / \"all_generations_v1.json\"\n",
    "\n",
    "# Create the complete workflow JSON\n",
    "complete_workflow = {\n",
    "    \"version\": 1.0,\n",
    "    \"state\": {},\n",
    "    \"nodes\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"type\": \"LoadImage\",\n",
    "            \"pos\": [50, 200],\n",
    "            \"size\": [315, 98],\n",
    "            \"flags\": {},\n",
    "            \"order\": 0,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"LoadImage\"},\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"IMAGE\",\n",
    "                    \"type\": \"IMAGE\",\n",
    "                    \"links\": [5],\n",
    "                    \"slot_index\": 0\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"MASK\",\n",
    "                    \"type\": \"MASK\",\n",
    "                    \"links\": [],\n",
    "                    \"slot_index\": 1\n",
    "                }\n",
    "            ],\n",
    "            \"widgets_values\": [str(PATHS[\"my_photo\"])]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"type\": \"LoadImage\",\n",
    "            \"pos\": [50, 400],\n",
    "            \"size\": [315, 98],\n",
    "            \"flags\": {},\n",
    "            \"order\": 1,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"LoadImage\"},\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"IMAGE\",\n",
    "                    \"type\": \"IMAGE\",\n",
    "                    \"links\": [6],\n",
    "                    \"slot_index\": 0\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"MASK\",\n",
    "                    \"type\": \"MASK\",\n",
    "                    \"links\": [],\n",
    "                    \"slot_index\": 1\n",
    "                }\n",
    "            ],\n",
    "            \"widgets_values\": [str(test_donor)]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"type\": \"CheckpointLoaderSimple\",\n",
    "            \"pos\": [50, 0],\n",
    "            \"size\": [300, 100],\n",
    "            \"flags\": {},\n",
    "            \"order\": 2,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"},\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [\n",
    "                {\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [7], \"slot_index\": 0},\n",
    "                {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [8, 15], \"slot_index\": 1},\n",
    "                {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [9], \"slot_index\": 2}\n",
    "            ],\n",
    "            \"widgets_values\": [\"sd_xl_turbo_1.0.safetensors\"]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 4,\n",
    "            \"type\": \"CLIPTextEncode\",\n",
    "            \"pos\": [400, 0],\n",
    "            \"size\": [400, 100],\n",
    "            \"flags\": {},\n",
    "            \"order\": 3,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"},\n",
    "            \"inputs\": [\n",
    "                {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 8, \"slot_index\": 0}\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [10], \"slot_index\": 0}\n",
    "            ],\n",
    "            \"widgets_values\": [\"professional passport photo of a healthy 12 month old baby, front facing portrait, clean natural lighting, clear face, soft natural skin, white background, sharp focus, high quality photograph, Canon camera, photorealistic, no editing, neutral expression\"]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 5,\n",
    "            \"type\": \"KSampler\",\n",
    "            \"pos\": [800, 200],\n",
    "            \"size\": [400, 400],\n",
    "            \"flags\": {},\n",
    "            \"order\": 4,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"KSampler\"},\n",
    "            \"inputs\": [\n",
    "                {\"name\": \"model\", \"type\": \"MODEL\", \"link\": 7, \"slot_index\": 0},\n",
    "                {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 10, \"slot_index\": 1},\n",
    "                {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 11, \"slot_index\": 2},\n",
    "                {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 12, \"slot_index\": 3}\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [13], \"slot_index\": 0}\n",
    "            ],\n",
    "            \"widgets_values\": [\n",
    "                seeds[0],                # seed\n",
    "                \"randomize\",            # control_after_generate\n",
    "                30,                     # steps\n",
    "                7.5,                    # cfg\n",
    "                \"euler_ancestral\",                # sampler_name\n",
    "                \"normal\",               # scheduler\n",
    "                0.8                     # denoise\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 8,\n",
    "            \"type\": \"EmptyLatentImage\",\n",
    "            \"pos\": [600, 300],\n",
    "            \"size\": [315, 98],\n",
    "            \"flags\": {},\n",
    "            \"order\": 3,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"EmptyLatentImage\"},\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [\n",
    "                {\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [12], \"slot_index\": 0}\n",
    "            ],\n",
    "            \"widgets_values\": [512, 512, 1]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 9,\n",
    "            \"type\": \"CLIPTextEncode\",\n",
    "            \"pos\": [400, 150],\n",
    "            \"size\": [400, 100],\n",
    "            \"flags\": {},\n",
    "            \"order\": 3,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"},\n",
    "            \"inputs\": [\n",
    "                {\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 15, \"slot_index\": 0}\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [11], \"slot_index\": 0}\n",
    "            ],\n",
    "            \"widgets_values\": [\"distorted, deformed, ugly, mutation, blurry, grainy, noisy, oversaturated, overprocessed, artificial, harsh lighting, unrealistic colors, plastic skin, extreme contrast, overexposed, surreal, watercolor, painting, illustration, artificial HDR, oversharpened\"]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 6,\n",
    "            \"type\": \"VAEDecode\",\n",
    "            \"pos\": [1200, 200],\n",
    "            \"size\": [200, 100],\n",
    "            \"flags\": {},\n",
    "            \"order\": 5,\n",
    "            \"mode\": 0,\n",
    "            \"properties\": {\"Node name for S&R\": \"VAEDecode\"},\n",
    "            \"inputs\": [\n",
    "                {\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 13, \"slot_index\": 0},\n",
    "                {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 9, \"slot_index\": 1}\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [14], \"slot_index\": 0}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 7,\n",
    "            \"type\": \"SaveImage\",\n",
    "            \"pos\": [1400, 200],\n",
    "            \"size\": [400, 100],\n",
    "            \"flags\": {},\n",
    "            \"order\": 8,\n",
    "            \"mode\": 0,\n",
    "            \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 14, \"slot_index\": 0}],\n",
    "            \"outputs\": [],\n",
    "            \"properties\": {\"Node name for S&R\": \"SaveImage\"},\n",
    "            \"widgets_values\": [\"aug_gpt_4_gem_wo_baby_1\"]  # Just the filename, no path\n",
    "        }\n",
    "    ],\n",
    "    \"links\": [\n",
    "        {\"id\": 5, \"origin_id\": 1, \"origin_slot\": 0, \"target_id\": 5, \"target_slot\": 0, \"type\": \"IMAGE\"},\n",
    "        {\"id\": 6, \"origin_id\": 2, \"origin_slot\": 0, \"target_id\": 5, \"target_slot\": 1, \"type\": \"IMAGE\"},\n",
    "        {\"id\": 7, \"origin_id\": 3, \"origin_slot\": 0, \"target_id\": 5, \"target_slot\": 0, \"type\": \"MODEL\"},\n",
    "        {\"id\": 8, \"origin_id\": 3, \"origin_slot\": 1, \"target_id\": 4, \"target_slot\": 0, \"type\": \"CLIP\"},\n",
    "        {\"id\": 9, \"origin_id\": 3, \"origin_slot\": 2, \"target_id\": 6, \"target_slot\": 1, \"type\": \"VAE\"},\n",
    "        {\"id\": 10, \"origin_id\": 4, \"origin_slot\": 0, \"target_id\": 5, \"target_slot\": 1, \"type\": \"CONDITIONING\"},\n",
    "        {\"id\": 11, \"origin_id\": 9, \"origin_slot\": 0, \"target_id\": 5, \"target_slot\": 2, \"type\": \"CONDITIONING\"},\n",
    "        {\"id\": 12, \"origin_id\": 8, \"origin_slot\": 0, \"target_id\": 5, \"target_slot\": 3, \"type\": \"LATENT\"},\n",
    "        {\"id\": 13, \"origin_id\": 5, \"origin_slot\": 0, \"target_id\": 6, \"target_slot\": 0, \"type\": \"LATENT\"},\n",
    "        {\"id\": 14, \"origin_id\": 6, \"origin_slot\": 0, \"target_id\": 7, \"target_slot\": 0, \"type\": \"IMAGE\"},\n",
    "        {\"id\": 15, \"origin_id\": 3, \"origin_slot\": 1, \"target_id\": 9, \"target_slot\": 0, \"type\": \"CLIP\"}\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup complete!\n",
      "Test donor: aug_gpt_4_gem_wo.jpeg\n",
      "Output directory: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings/donor_logs/aug_gpt_4_gem_wo/v1\n",
      "Seeds to be used: [2103594951, 1025833320, 95593290]\n",
      "\n",
      "Workflow saved to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings/donor_logs/aug_gpt_4_gem_wo/workflow.json\n",
      "\n",
      "To generate images:\n",
      "1. Go to ComfyUI interface at http://localhost:8188\n",
      "2. Click 'Load' and select the workflow file at: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/outputs/generated_offsprings/donor_logs/aug_gpt_4_gem_wo/workflow.json\n",
      "3. Click 'Queue' to generate the first baby photo\n",
      "\n",
      "After first generation completes:\n",
      "4. Change the seed to 1025833320 and filename to '_baby_2'\n",
      "5. Generate again\n",
      "6. Change the seed to 95593290 and filename to '_baby_3'\n",
      "7. Generate one final time\n"
     ]
    }
   ],
   "source": [
    "# Save the workflow\n",
    "workflow_path = donor_output_dir.parent / \"workflow.json\"\n",
    "with open(workflow_path, \"w\") as f:\n",
    "    json.dump(complete_workflow, f, indent=2)\n",
    "\n",
    "# Create metadata for our test generation\n",
    "test_metadata = create_generation_metadata(\n",
    "    test_donor.name,\n",
    "    seeds=seeds,\n",
    ")\n",
    "\n",
    "# Save initial metadata\n",
    "donor_metadata_path = donor_output_dir.parent / \"metadata_v1.json\"\n",
    "with open(donor_metadata_path, \"w\") as f:\n",
    "    json.dump(test_metadata, f, indent=2)\n",
    "\n",
    "# Update main logs\n",
    "update_main_logs(test_metadata, csv_log_path, json_log_path)\n",
    "\n",
    "print(f\"\\nSetup complete!\")\n",
    "print(f\"Test donor: {test_donor.name}\")\n",
    "print(f\"Output directory: {donor_output_dir}\")\n",
    "print(f\"Seeds to be used: {seeds}\")\n",
    "print(f\"\\nWorkflow saved to: {workflow_path}\")\n",
    "print(\"\\nTo generate images:\")\n",
    "print(\"1. Go to ComfyUI interface at http://localhost:8188\")\n",
    "print(\"2. Click 'Load' and select the workflow file at:\", workflow_path)\n",
    "print(\"3. Click 'Queue' to generate the first baby photo\")\n",
    "print(\"\\nAfter first generation completes:\")\n",
    "print(\"4. Change the seed to\", seeds[1], \"and filename to '_baby_2'\")\n",
    "print(\"5. Generate again\")\n",
    "print(\"6. Change the seed to\", seeds[2], \"and filename to '_baby_3'\")\n",
    "print(\"7. Generate one final time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing\n",
    "Testing with 5 donors first to ensure everything works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Setup\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update paths\n",
    "COMFY_PATH = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI\")\n",
    "COMFY_OUTPUT = COMFY_PATH / \"output\"\n",
    "DONORS_PATH = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/comfyui_source_files\")\n",
    "MY_PHOTO = Path(\"/Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/data/input/cindy.jpg\")\n",
    "BASE_WORKFLOW_PATH = COMFY_PATH / \"user/default/workflows/base_workflow.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def verify_saved_image(output_path: Path, donor_id: str, variation: int) -> bool:\n",
    "    \"\"\"Verify that image was saved and is valid\"\"\"\n",
    "    expected_file = list(output_path.glob(f\"{donor_id}_baby_{variation}*.png\"))\n",
    "    \n",
    "    if not expected_file:\n",
    "        print(f\"❌ Warning: No output file found for {donor_id} variation {variation}\")\n",
    "        return False\n",
    "        \n",
    "    if expected_file[0].stat().st_size == 0:\n",
    "        print(f\"❌ Warning: Empty file generated for {donor_id} variation {variation}\")\n",
    "        return False\n",
    "        \n",
    "    print(f\"✓ Successfully saved: {expected_file[0].name}\")\n",
    "    return True\n",
    "\n",
    "def generate_random_seeds(count=3):\n",
    "    \"\"\"Generate list of random seeds for multiple generations\"\"\"\n",
    "    return [random.randint(1, 2**31 - 1) for _ in range(count)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base workflow from: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/user/default/workflows/base_workflow.json\n",
      "Successfully loaded base workflow\n"
     ]
    }
   ],
   "source": [
    "# Load and modify base workflow\n",
    "print(f\"Loading base workflow from: {BASE_WORKFLOW_PATH}\")\n",
    "if not BASE_WORKFLOW_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Base workflow not found at: {BASE_WORKFLOW_PATH}\")\n",
    "\n",
    "with open(BASE_WORKFLOW_PATH, 'r') as f:\n",
    "    base_workflow = json.load(f)\n",
    "print(\"Successfully loaded base workflow\")\n",
    "\n",
    "def modify_workflow_for_donor(workflow: dict, donor_path: str, seed: int, variation: int) -> dict:\n",
    "    \"\"\"Modify workflow for specific donor and variation\"\"\"\n",
    "    modified = workflow.copy()\n",
    "    \n",
    "    # Update LoadImage nodes\n",
    "    for node in modified['nodes']:\n",
    "        if node['type'] == 'LoadImage':\n",
    "            if node['id'] == 1:  # Your photo\n",
    "                node['widgets_values'] = [str(MY_PHOTO)]\n",
    "            elif node['id'] == 2:  # Donor photo\n",
    "                node['widgets_values'] = [str(donor_path)]\n",
    "        \n",
    "        # Update KSampler parameters\n",
    "        elif node['type'] == 'KSampler':\n",
    "            node['widgets_values'] = [\n",
    "                seed,           # seed\n",
    "                \"randomize\",    # control_after_generate\n",
    "                30,            # steps\n",
    "                7.5,           # cfg\n",
    "                \"euler\",       # sampler_name\n",
    "                \"normal\",      # scheduler\n",
    "                0.8            # denoise\n",
    "            ]\n",
    "        \n",
    "        # Update SaveImage filename\n",
    "        elif node['type'] == 'SaveImage':\n",
    "            donor_id = Path(donor_path).stem\n",
    "            node['widgets_values'] = [f\"{donor_id}_baby_{variation}\"]\n",
    "    \n",
    "    return modified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Batch Processing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Will process these donors:\n",
      "1. aug_cla_2_gem_wo.jpeg\n",
      "2. aug_cla_3_gem_wo.jpeg\n",
      "3. aug_cla_4_gem_wo.jpeg\n",
      "4. aug_cla_5_gem_wo.jpeg\n",
      "5. aug_cla_6_gem_demo.jpeg\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 donors\n",
    "test_donors = sorted(list(DONORS_PATH.glob(\"*.jpeg\")))[:5]\n",
    "\n",
    "print(\"\\nWill process these donors:\")\n",
    "for i, donor in enumerate(test_donors, 1):\n",
    "    print(f\"{i}. {donor.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Test Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing donor 1/5: aug_cla_2_gem_wo.jpeg\n",
      "\n",
      "Generating variation 1/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_2_gem_wo_v1.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_2_gem_wo_baby_1_00001_.png\n",
      "\n",
      "Generating variation 2/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_2_gem_wo_v2.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_2_gem_wo_baby_2_00001_.png\n",
      "\n",
      "Generating variation 3/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_2_gem_wo_v3.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_2_gem_wo_baby_3_00001_.png\n",
      "\n",
      "✓ Completed all variations for aug_cla_2_gem_wo.jpeg\n",
      "\n",
      "==================================================\n",
      "Processing donor 2/5: aug_cla_3_gem_wo.jpeg\n",
      "\n",
      "Generating variation 1/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_3_gem_wo_v1.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_3_gem_wo_baby_1_00001_.png\n",
      "\n",
      "Generating variation 2/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_3_gem_wo_v2.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_3_gem_wo_baby_2_00001_.png\n",
      "\n",
      "Generating variation 3/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_3_gem_wo_v3.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_3_gem_wo_baby_3_00001_.png\n",
      "\n",
      "✓ Completed all variations for aug_cla_3_gem_wo.jpeg\n",
      "\n",
      "==================================================\n",
      "Processing donor 3/5: aug_cla_4_gem_wo.jpeg\n",
      "\n",
      "Generating variation 1/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_4_gem_wo_v1.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_4_gem_wo_baby_1_00001_.png\n",
      "\n",
      "Generating variation 2/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_4_gem_wo_v2.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_4_gem_wo_baby_2_00001_.png\n",
      "\n",
      "Generating variation 3/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_4_gem_wo_v3.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_4_gem_wo_baby_3_00001_.png\n",
      "\n",
      "✓ Completed all variations for aug_cla_4_gem_wo.jpeg\n",
      "\n",
      "==================================================\n",
      "Processing donor 4/5: aug_cla_5_gem_wo.jpeg\n",
      "\n",
      "Generating variation 1/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_5_gem_wo_v1.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "❌ Warning: No output file found for aug_cla_5_gem_wo variation 1\n",
      "\n",
      "Generating variation 2/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_5_gem_wo_v2.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_5_gem_wo_baby_2_00001_.png\n",
      "\n",
      "Generating variation 3/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_5_gem_wo_v3.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_5_gem_wo_baby_3_00001_.png\n",
      "\n",
      "✓ Completed all variations for aug_cla_5_gem_wo.jpeg\n",
      "\n",
      "==================================================\n",
      "Processing donor 5/5: aug_cla_6_gem_demo.jpeg\n",
      "\n",
      "Generating variation 1/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_6_gem_demo_v1.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_6_gem_demo_baby_1_00001_.png\n",
      "\n",
      "Generating variation 2/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_6_gem_demo_v2.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_6_gem_demo_baby_2_00001_.png\n",
      "\n",
      "Generating variation 3/3\n",
      "✓ Saved workflow to: /Users/cindylinsf/Documents/CCI/THESIS/Msc_Thesis_Project_Files/models/ComfyUI/output/workflows/aug_cla_6_gem_demo_v3.json\n",
      "⚠️ Please load this workflow in ComfyUI and click 'Queue'\n",
      "✓ Successfully saved: aug_cla_6_gem_demo_baby_3_00001_.png\n",
      "\n",
      "✓ Completed all variations for aug_cla_6_gem_demo.jpeg\n",
      "\n",
      "🎉 Batch processing complete!\n"
     ]
    }
   ],
   "source": [
    " def process_test_batch():\n",
    "    total_donors = len(test_donors)\n",
    "    \n",
    "    for donor_idx, donor_path in enumerate(test_donors, 1):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing donor {donor_idx}/{total_donors}: {donor_path.name}\")\n",
    "        \n",
    "        # Generate 3 variations for this donor\n",
    "        seeds = generate_random_seeds(3)\n",
    "        \n",
    "        for variation in range(1, 4):\n",
    "            print(f\"\\nGenerating variation {variation}/3\")\n",
    "            \n",
    "            # Modify workflow for this variation\n",
    "            workflow = modify_workflow_for_donor(\n",
    "                base_workflow,\n",
    "                str(donor_path),\n",
    "                seeds[variation-1],\n",
    "                variation\n",
    "            )\n",
    "            \n",
    "            # Save workflow for this variation\n",
    "            workflow_path = COMFY_OUTPUT / \"workflows\" / f\"{donor_path.stem}_v{variation}.json\"\n",
    "            workflow_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            with open(workflow_path, 'w') as f:\n",
    "                json.dump(workflow, f, indent=2)\n",
    "            \n",
    "            print(f\"✓ Saved workflow to: {workflow_path}\")\n",
    "            print(f\"⚠️ Please load this workflow in ComfyUI and click 'Queue'\")\n",
    "            \n",
    "            # Wait for user confirmation before continuing\n",
    "            input(\"Press Enter after the image has been generated...\")\n",
    "            \n",
    "            # Verify saved image\n",
    "            verify_saved_image(COMFY_OUTPUT, donor_path.stem, variation)\n",
    "            \n",
    "            # Brief pause between generations\n",
    "            time.sleep(2)\n",
    "        \n",
    "        print(f\"\\n✓ Completed all variations for {donor_path.name}\")\n",
    "    \n",
    "    print(\"\\n🎉 Batch processing complete!\")\n",
    "\n",
    "# Run with:\n",
    "process_test_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Automated Batch Processing\n",
    "Setting up automated generation using ComfyUI's WebSocket API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datetime import datetime\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComfyUIAutomator:\n",
    "    def __init__(self, host=\"127.0.0.1\", port=8188):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.base_url = f\"http://{host}:{port}\"\n",
    "        \n",
    "    def verify_server(self):\n",
    "        \"\"\"Verify ComfyUI server is running and accessible\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.base_url}/history\")\n",
    "            if response.status_code == 200:\n",
    "                print(\"✓ ComfyUI server is running and accessible\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"❌ ComfyUI server returned unexpected status code:\", response.status_code)\n",
    "                return False\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"❌ Could not connect to ComfyUI server. Is it running?\")\n",
    "            return False\n",
    "\n",
    "    def queue_prompt(self, workflow):\n",
    "        \"\"\"Queue a prompt using HTTP API\"\"\"\n",
    "        try:\n",
    "            # Queue the prompt\n",
    "            response = requests.post(f\"{self.base_url}/prompt\", json=workflow)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"❌ Failed to queue prompt: {response.status_code}\")\n",
    "                return False\n",
    "                \n",
    "            prompt_id = response.json()['prompt_id']\n",
    "            print(f\"✓ Prompt queued (ID: {prompt_id})\")\n",
    "            \n",
    "            # Wait for generation to complete\n",
    "            while True:\n",
    "                status_response = requests.get(f\"{self.base_url}/history\")\n",
    "                if status_response.status_code != 200:\n",
    "                    print(\"❌ Failed to get status\")\n",
    "                    return False\n",
    "                    \n",
    "                history = status_response.json()\n",
    "                if prompt_id in history:\n",
    "                    if 'outputs' in history[prompt_id]:\n",
    "                        print(\"✓ Generation completed\")\n",
    "                        return True\n",
    "                    elif 'error' in history[prompt_id]:\n",
    "                        print(f\"❌ Generation failed: {history[prompt_id]['error']}\")\n",
    "                        return False\n",
    "                        \n",
    "                print(\"⏳ Waiting for generation...\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "def process_batch(donors, base_workflow):\n",
    "    automator = ComfyUIAutomator()\n",
    "    batch_start = time.time()\n",
    "    \n",
    "    for donor_idx, donor_path in enumerate(donors, 1):\n",
    "        donor_start = time.time()\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] Processing donor {donor_idx}/{len(donors)}: {donor_path.name}\")\n",
    "        \n",
    "        for variation in range(1, 4):\n",
    "            print(f\"\\nGenerating variation {variation}/3\")\n",
    "            \n",
    "            # Modify workflow\n",
    "            workflow = base_workflow.copy()\n",
    "            for node in workflow['nodes']:\n",
    "                if node['type'] == 'KSampler':\n",
    "                    node['widgets_values'] = [\n",
    "                        random.randint(1, 2**31 - 1),  # random seed\n",
    "                        \"randomize\",\n",
    "                        30,                    # steps\n",
    "                        7.5,                   # cfg\n",
    "                        \"euler\",               # sampler\n",
    "                        \"normal\",\n",
    "                        0.8                    # denoise\n",
    "                    ]\n",
    "                elif node['type'] == 'SaveImage':\n",
    "                    node['widgets_values'] = [\n",
    "                        f\"{Path(donor_path).stem}_baby_{variation}\",\n",
    "                        \"\"  # prevent auto-numbering\n",
    "                    ]\n",
    "            \n",
    "            # Queue and wait for completion\n",
    "            success = automator.queue_prompt(workflow)\n",
    "            if not success:\n",
    "                print(f\"❌ Failed to generate variation {variation}\")\n",
    "            else:\n",
    "                print(f\"✓ Successfully generated variation {variation}\")\n",
    "            \n",
    "            # Brief pause between generations\n",
    "            time.sleep(1)\n",
    "        \n",
    "        donor_elapsed = time.time() - donor_start\n",
    "        print(f\"✓ Completed donor {donor_path.name} in {donor_elapsed:.1f}s\")\n",
    "    \n",
    "    batch_elapsed = time.time() - batch_start\n",
    "    print(f\"\\n🎉 Batch processing completed in {batch_elapsed:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function\n",
    "def run_test(num_donors=1):\n",
    "    # Create automator instance\n",
    "    automator = ComfyUIAutomator()\n",
    "    \n",
    "    # Verify server is running\n",
    "    if not automator.verify_server():\n",
    "        print(\"Please make sure ComfyUI server is running first!\")\n",
    "        return\n",
    "    \n",
    "    # Load base workflow\n",
    "    try:\n",
    "        with open(BASE_WORKFLOW_PATH, 'r') as f:\n",
    "            base_workflow = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading workflow: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Get specified number of donors\n",
    "    test_donors = sorted(list(DONORS_PATH.glob(\"*.jpeg\")))[:num_donors]\n",
    "    \n",
    "    print(f\"Testing automation with {num_donors} donor(s):\")\n",
    "    for donor in test_donors:\n",
    "        print(f\"- {donor.name}\")\n",
    "    \n",
    "    # Process batch\n",
    "    process_batch(test_donors, base_workflow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:48:07] Starting test generation...\n",
      "✓ ComfyUI server is running and accessible\n",
      "Testing automation with 1 donor(s):\n",
      "- aug_cla_2_gem_wo.jpeg\n",
      "\n",
      "==================================================\n",
      "[20:48:07] Processing donor 1/1: aug_cla_2_gem_wo.jpeg\n",
      "\n",
      "Generating variation 1/3\n",
      "❌ Failed to queue prompt: 400\n",
      "❌ Failed to generate variation 1\n",
      "\n",
      "Generating variation 2/3\n",
      "❌ Failed to queue prompt: 400\n",
      "❌ Failed to generate variation 2\n",
      "\n",
      "Generating variation 3/3\n",
      "❌ Failed to queue prompt: 400\n",
      "❌ Failed to generate variation 3\n",
      "✓ Completed donor aug_cla_2_gem_wo.jpeg in 3.0s\n",
      "\n",
      "🎉 Batch processing completed in 3.0s\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting test generation...\")\n",
    "run_test(num_donors=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
